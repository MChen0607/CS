# 同步 & 死锁

# 1. 同步

产生同步的原因：进程并发执行，如果不同的进程需要访问共享内存，那么它们的访问顺序可能会影响结果

竞争条件：多个进程并发访问和操作同一个数据，并且执行结果和特定的访问顺序有关。那么为了防止竞争，需要保证每次只有一个进程能够访问该内存——那么要求**进程间进行同步**

eg：多个进程进行i++操作，而i是存放在共享内存中的，如果没有做好同步，那么i的结果可能小于总循环次数

## 1.1 易混淆的概念

同步：**进程间的直接制约关系，合作关系**，为了完成某个任务而建立的多个进程，这两个进程需要在某个位置上协调进度，那么需要相互等待、传递信息而产生的制约关系

由合作产生的直接制约关系。——即，两个进行需要在某个程序结点进行信息传递，但是由于进程调度等问题，进程A速度比B快，所以它先到了该点，那么需要等待B执行到对应的点，这个就是制约关系。

eg：进程A向缓冲区发送数据，进程B从 缓冲区读取数据，如果进程A没有发送数据，那么进程B就阻塞在这边了，那么这个就是同步点

互斥：**进程间的间接制约关系**，一个进程进入临界区使用资源，那么其他的线程需要进行等待。

<img src="C:\Users\surface\AppData\Roaming\Typora\typora-user-images\image-20210330231419346.png" alt="image-20210330231419346" style="zoom:80%;" />

## 1.2临界区

每个进程有一段代码（位置可能不同）——临界区。所以临界区是一段代码

在该临界区中会去修改共享变量、文件等共享的内容。

要求是：一个线程在临界区中执行，那么其他线程不能进入。——在具体代码中是，如果两个线程访问的是同一个资源，那么必须要互斥，如果不是同一个资源，其实是可以同时进行的，但是由于不知道os中是否存在其他线程在访问该共享资源，所以统一要求：如果在访问共享资源，那么该代码段就是临界区，需要互斥访问。

为了互斥访问临界资源，每个进程在进入临界区之前，需要先进行检查。

```
// entry section
// critical section;
// exit section
```

实现临界区的关键：进入区和退出区。

## 1.3 Peterson算法

是一个经典的，解决临界区互斥的问题：

有两个共享变量

```c
int turn;				// = i，表示p_i可以执行
boolean flag[2];		// flag[i] = true 表示p_i想要执行
```

turn只有两种取值0/1，分别代表线程0和线程1。当turn==0，表示线程0可以进入临界区

```c
// 线程i
do{
    flag[i] = true;			// 希望进入临界区
    turn = j;				// 如果线程j想要进入，那么给它进
    while(flag[j] && turn == j);		// 此时flag[j]=true且turn=j，表示线程j正在执行
    
    临界区					// 想要进入临界区，必须要flag[j]==false or turn=i，前者表示线程j从临界区出来了；后者表示j要进入临界区，但是机会给i了
        
    flag[i] = false;   
}while(true);

// 线程j
do{
    flag[j] = true;			// 表示自己希望能进入临界区
    turn = i;				// 表示如果线程i想要进入临界区（flag[i] = true），就给他进，那么满足flag[i] = true && turn=i，线程i就进入临界区
    while(flag[i] && turn == i);
    
    临界区
    
    flag[j] = false;
}while(true);
```

所以最极端情况，线程i、j同时想要进入临界区，所以设置了fla=true，然后同时设置了turn=对方，但是只有一个有效，有效的那个就能进入临界区

证明：

1. 互斥性：

   如果想要两个线程同时在临界区，需要满足`flag[i]=flag[j]=true`，而进入临界区的要求是`对方的flag=false or turn=自己`，所以两个条件总结就是，turn必须同时等于0和1，这是不可能的，所以能够实现互斥。

2. 有限等待：

   如果线程i需要进入临界区，但是由于抢占失败，所以线程j在执行。那么线程i在while中自循环，那么线程j执行结束之后退出临界区，线程i马上能够进入临界区，所以最多等待1次就能进入

3. 进入：（如果临界区空闲，且有线程想要进入，那么要立即选择进行进入，不能延迟）

   可以看到如果线程j从临界区中释放，而且线程i在while等待，那么修改flag[j]状态，线程i就能进入

存在的问题：对于现代处理器，可能存在重排序的问题，由于flag和turn不存在联系，所以两个赋值语句存在重排序的可能

从而导致：两个都能进入临界区：

<img src="C:\Users\surface\AppData\Roaming\Typora\typora-user-images\image-20210331093350699.png" alt="image-20210331093350699" style="zoom:80%;" />

为了解决这个需要设置内存屏障：内存屏障能保证，在这个之前的所有load/store操作全部完成了，这样才能继续下面的操作。

对于上面的，可以在flag和turn之间加一个内存屏障，那么它们不能重排序了，所以就不会存在问题。

## 1.4 硬件同步

主要是用到了CAS，硬件能够保证CAS的操作是原子性的，那么就能实现互斥性。

```c
do{
    while(compareAndSet(&lock, 0, 1) != 0);	// 只有lock值等于0，才能修改为1，比较并修改保证原子性；那么竞争时只有一个线程能保证修改成功，其他均死循环
    
    临界区
    
    lock = 0;			// 由于只有一个线程才能进入，那么该修改不需要用CAS也能保证原子性。执行完成后又可以开始竞争
}while(true);
```

## 1.5 互斥锁（mutex Lock）

就是锁，在进入临界区之前需要获得锁，如果获得锁，那么能进入；如果不能，那么就自旋等待。退出临界区需要释放锁

API是：acquire()获取锁，如果获取失败那么将会挂起

​			 release()释放锁

```c
void acquire(){
    while(!available);
    available = true;
}
```

——可以看到获取锁的方法内部是忙等待（自旋锁），不需要进行上下文切换，但是一直占用当前时间片的CPU。

如果锁很快能够得到那么可以用互斥锁；如果长时间得不到，需要将自己挂起，否则太消耗CPU了

## 1.6 信号量

### 1.6.1 概念

信号量是一个整型变量，可以对其执行 down 和 up 操作，也就是常见的 P 和 V 操作。

- P：wait()： 如果信号量大于 0 ，执行 -1 操作；如果信号量等于 0，进程睡眠，等待信号量大于 0；
- V：signal()：对信号量执行 +1 操作，唤醒睡眠的进程让其完成 wait操作。

```c
int S;
wait(S){
    while(s <= 0);			// 忙等待
    s--;
}

signal(S){
    s++;
}
```

wait和 signal操作需要被**设计成原语，不可分割，通常的做法是在执行这些操作的时候屏蔽中断**。

信号量可以分为：

1. **计数信号量**：**初始值就是可用资源数量**，wait就是--；signal就是++，当资源余量减少到0，表示所有资源都在使用中，那么线程需要等待，直到信号量>0

2. **二进制信号量**：值只能为0/1，那么就称为互斥量，类似于互斥锁（如果没有提供互斥锁，可以用互斥量来替代）

   0 表示临界区已经加锁，1 表示临界区解锁。

```c
typedef int semaphore;
semaphore mutex = 1;
void P1() {
    wait(&mutex);
    // 临界区
    signal(&mutex);
}

void P2() {
    wait(&mutex);
    // 临界区
    signald(&mutex);
}
```

也可以用信号量实现同步问题：要求只有在线程执行完s1之后，才能执行线程2的s2

```c
int semaphore = 0;			// 初始先执行wait就会被挂起
// 线程1
S1;
signal(semaphore);			// 只有等到s1执行完成，释放信号量才行

// 线程2
wait(semaphore);			// 一旦先执行，就会被阻塞在这里
S2;
```

### 1.6.2 实现

数据结构：

```c
typedef struct{
    int value;
    struct Process* list;
}
```

可以看到如果有等待的线程需要将其加入到信号量的等待队列上，而该线程是处于阻塞状态。而其他线程在释放信号量的时候，会唤醒一个or全部阻塞队列

信号量可以是负数：表示正在等待的线程数。等待队列的排序方式可以是FIFO、优先级等

关键是：**信号量的操作应该保证原子性**（这也是一个临界区问题）

- 对于单处理器：只需要屏蔽中断即可，因为屏蔽中断，当前线程在时间片内就不被打断，那么就能保证执行的原子性
- 对于多处理器：需要屏蔽所有处理器的中断——会严重影响性能。所以可以采用CAS/自旋锁

所以，wait/signal中还是存在忙等待，但是被限制在这两个方法内，且代码很短，所以如果临界区被很少使用，那么忙等待时间很少；但是如果花费很长时间在临界区，那么忙等待耗时很可怕

### 1.6.3 使用

**使用信号量实现生产者-消费者问题**

问题描述：使用一个缓冲区来保存物品，只有缓冲区没有满，生产者才可以放入物品；只有缓冲区不为空，消费者才可以拿走物品。

因为缓冲区属于临界资源，因此需要使用一个互斥量 mutex 来控制对缓冲区的互斥访问。

为了同步生产者和消费者的行为，需要记录缓冲区中物品的数量。数量可以使用信号量来进行统计，这里需要使用两个信号量：empty 记录空缓冲区的数量，full 记录满缓冲区的数量。其中，empty 信号量是在生产者进程中使用，当 empty 不为 0 时，生产者才可以放入物品；full 信号量是在消费者进程中使用，当 full 信号量不为 0 时，消费者才可以取走物品。

注意，**不能先对缓冲区进行加锁，再测试信号量**。也就是说，不能先执行 down(mutex) 再执行 down(empty)。如果这么做了，那么可能会出现这种情况：生产者对缓冲区加锁后，执行 down(empty) 操作，发现 empty = 0，此时生产者睡眠。消费者不能进入临界区，因为生产者对缓冲区加锁了，消费者就无法执行 up(empty) 操作，empty 永远都为 0，导致生产者永远等待下，不会释放锁，消费者因此也会永远等待下去。——出现死锁

```c
#define N 100
typedef int semaphore;
semaphore mutex = 1;
semaphore empty = N;				// 记录缓冲区剩余空闲数
semaphore full = 0;					// 记录缓冲区中内容个数

void producer() {
    while(TRUE) {
        int item = produce_item();
        down(&empty);				// 先减少空闲的量(如果empty=0，表示缓冲区满了，不能add了)
        down(&mutex);				// 再加锁，进入临界区
        insert_item(item);
        up(&mutex);
        up(&full);				
    }
}

void consumer() {
    while(TRUE) {
        down(&full);			// 先减少满的量（如果full=0，表示缓冲区为空，不能获取数据）
        down(&mutex);
        int item = remove_item();
        consume_item(item);
        up(&mutex);
        up(&empty);
    }
}
```

### 1.6.4 信号量存在的问题

#### 1.6.4.1 死锁

互相等待对方释放信号量，然后就死锁了

```c
P0:
wait(s);				//--1
wait(q);				// 等p1释放q
.....
signal(q);
signal(s);

P1:
wait(q);				//--2，然后就死锁了
wait(s);				// 等p0释放s
.....
signal(s);
signal(q);
```

还有一个问题是饥饿，这主要和信号量的阻塞队列有关，如果队列是优先级队列 or LCFS，那么就会发生饥饿现象

#### 1.6.4.2 优先级反转

发生在2个以上的优先级调度操作系统中

描述：低优先级线程A，获得了共享资源，正在执行；而高优先级的线程C，也想要获得资源，所以会被阻塞，出现C等待A的现象（符合要求）；而中优先级线程B，不需要共享资源，但是由于B比A优先级高，所以抢占了A开始执行，所以出现了**B比C优先级低，但是B先执行的现象**——优先级反转。

有两种解决方案：优先级继承、优先级天花板。

- 优先级继承，一个线程一旦被阻塞在锁的等待队列上时，如果该线程优先级比获得锁的线程的优先级高，那么该线程需要暂时提高优先级为高优先级——即，获得锁的线程的优先级 = `max(自己的优先级，等待队列的最高优先级)`；释放锁之后，再将优先级降回来
- 优先级天花板：就是提前计算想要获得该锁的最高优先级线程的优先级数，一旦一个线程获得锁，就将其优先级升级到最高级

——这样就避免，低优先级的线程比高优先级的线程执行早了

## 1.7 管程

### 1.7.1 管程的概念

使用信号量机制实现的生产者消费者问题需要客户端代码做很多控制，容易出现问题，Peterson方法可能会出现指令重排序的问题，都不能保证代码的正确性。**管程把控制的代码独立出来**，不仅不容易出错，也使得客户端代码调用更容易。

管程由抽象数据类型ADT封装的一组数据和操作，然后进程只能通过调用API来实现对管程的调用。

管程有一个重要特性：**在一个时刻只能有一个进程使用管程**。**进程在无法继续执行的时候不能一直占用管程**，否则其它进程永远不能使用管程。

c 语言不支持管程，下面的示例代码使用了类 Pascal 语言来描述管程。示例代码的管程提供了 insert() 和 remove() 方法，客户端代码通过调用这两个方法来解决生产者-消费者问题。

```pascal
monitor ProducerConsumer
    integer i;
    condition c;

    procedure insert();
    begin
        // ...
    end;

    procedure remove();
    begin
        // ...
    end;
end monitor;
```

管程引入了 **条件变量** 以及相关的操作：**wait()** 和 **signal()** 来实现同步操作。

- 对条件变量执行 wait() 操作会导致调用进程阻塞，自己将自己挂起**把管程让出来给另一个进程持有**
- signal() 操作用于唤醒被阻塞的进程

管程中可以定义1个或者多个条件变量，它们都有wait/signal方法，那么存在一个问题

condition x,y;

线程A调用x.notify()，在x阻塞队列上等待的线程B将会被唤醒，由于管程中只能有一个线程在执行，那么该轮到谁执行呢？

- 唤醒并等待：线程A等待线程B执行完成离开管程后，才能继续在管程中执行
- 唤醒并继续：线程A唤醒B之后，可以继续执行，直到出了管程，线程B才开始能执行

<img src="C:\Users\surface\AppData\Roaming\Typora\typora-user-images\image-20210331133514153.png" alt="image-20210331133514153" style="zoom: 80%;" />

（类似于Java中的wait/notify，采用的是第二种方法）

### 1.7.2 管程的实现

用信号量的实现

```c
semaphore mutex;  // 初始值=1，看是否能够进入管程
semaphore next;   // 初始值=0，用来唤醒下一个等待的线程
int next_count = 0; // 记录在管程上等待的线程

// 进入管程的流程
wait(mutex);
…			 
body of P;
…
if (next_count > 0)			// 存在等待的线程，那么signal+1，那么其他线程可以进入管程
	signal(next)
else 
    signal(mutex);			// 离开管程


// 条件变量
semaphore x_sem; // 初始化为0
int x_count = 0;	

// x.wait()：在管程中将自己阻塞
x_count++;				// 记录阻塞个数
if (next_count > 0)		// 存在等待的线程，信号量+1，那么其他线程有机会进入管程（自己就会被抢占？）
    signal(next);
else					// 没有等待的线程，释放信号量，然后退出
    signal(mutex);
wait(x_sem);			// -1，将自己阻塞
x_count--;			// 被signal调度回来了

// x.signal()，唤醒其他线程
if (x_count > 0) {		// 只有存在等待线程才有唤醒的意义
    next_count++;
    signal(x_sem);			// x_sem++，然后能够唤醒前面调用wait(x_sem)的线程
    wait(next);
    next_count--;
}
```

### 1.7.3 管程的使用

Java中synchronized就是一个类管程。每个对象都有一个锁，当调用synchronized时候，就需要用到锁，如果获取锁成功就会进入临界区；如果获取锁失败，就会被挂在等待队列上，进入blocking状态

并且在获得锁之后也支持使用wait/notify方法，类似于管程的wait/signal方法

**使用管程实现生产者-消费者问题**

```Pascal
// 管程
monitor ProducerConsumer
    condition full, empty;
    integer count := 0;			// 缓冲区产品个数，初始为空
    condition c;

    procedure insert(item: integer);
    begin
        if count = N then wait(full);		// 缓冲区满了，挂起生产者
        insert_item(item);				// 到这一步，说明有空闲空间可以插入
        count := count + 1;
        if count = 1 then signal(empty);		// 如果原来为0，现在为1，那么可以唤醒等待的消费者
    end;

    function remove: integer;
    begin
        if count = 0 then wait(empty);			// 缓冲区为空，那么挂起消费者
        remove = remove_item;
        count := count - 1;
        if count = N -1 then signal(full);		// 原来为N，现在为N-1，又有空间了，可以唤醒生产者
    end;
end monitor;

// 生产者客户端
procedure producer
begin
    while true do
    begin
        item = produce_item;
        ProducerConsumer.insert(item);
    end
end;

// 消费者客户端
procedure consumer
begin
    while true do
    begin
        item = ProducerConsumer.remove;
        consume_item(item);
    end
end;
```

## 1.8 经典同步问题

生产者和消费者问题前面已经讨论过了。

### 1.8.1 哲学家进餐问题

五个哲学家围着一张圆桌，每个哲学家面前放着食物。哲学家的生活有两种交替活动：吃饭以及思考。当一个哲学家吃饭时，需要先拿起自己左右两边的两根筷子，并且一次只能拿起一根筷子。

——主要是解决：多个进程之间共享多个变量，且不会导致死锁或者饥饿现象。

共享数据：

```
semaphore chop[5];
```

下面是一种错误的解法，如果所有哲学家同时拿起左手边的筷子，那么所有哲学家都在等待其它哲学家吃完并释放自己手中的筷子，导致死锁。

```c
#define N 5

void philosopher(int i) {
    while(TRUE) {
        think();
        take(i);       // 拿起左边的筷子
        take((i+1)%N); // 拿起右边的筷子
        eat();
        put(i);
        put((i+1)%N);
    }
}
```

为了防止死锁的发生，可以设置两个条件：

- 必须同时拿起左右两根筷子；
- 只有在两个邻居都没有进餐的情况下才允许进餐。

```c
#define N 5
#define LEFT (i + N - 1) % N		// 左邻居
#define RIGHT (i + 1) % N			// 右邻居
#define THINKING 0					// 设置哲学家的3个状态
#define HUNGRY 1
#define EATING 2

typedef int semaphore;
int state[N];		// N个哲学家的状态
semaphore mutex = 1;		// 修改哲学家状态需要获取锁
semaphore s[N];			// 是否可以吃的信号量，默认为0，表示不可得

void philosopher(int i){
    think(i);
    take_two(i);			// 尝试拿到两个筷子，才能继续下去
    eat(i);
    put_two(i);			// 吃完后，放掉两个筷子
}

void take_two(i){			// 尝试获取两个筷子
    wait(mutex);			// 在互斥下进行：设置自己的状态、去读取状态
    state[i] = HUNGRY;		// 表示想要获取筷子
    check(i);
    signal(mutex);
    down(s[i]);			// 只有s[i]=1，才能吃
}

void eat(i){
    wait(mutex);
    state[i] = EATING;
    signal(mutex);
}

void put_two(i){
    wait(mutex);
    state[i] = THINKING;
    check_two(LEFT);
    check_left(RIGHT);
    signal(mutex);
}

// 检查两个邻居是否都没有用餐，且自己想吃——注意，由于要读取状态，所以必须在加锁的状态下读取
void check(i){
    if(state[i] == hungry && state[LEFT] != EATING && state[RIGHT] != EATING){
        state[i] = EATING;
        signal(s[i]);			// 表示可以吃了
    }
}
```

### 1.8.2 读者-写者问题

允许多个进程同时对数据进行读操作，但是不允许读和写以及写和写操作同时发生。

一个整型变量 count 记录在对数据进行**读操作的进程数量**，一个互斥量 count_mutex 用于对 count 加锁，一个互斥量 data_mutex 用于对读写的数据加锁。

```c
typedef int semaphore;
semaphore count_mutex = 1;		// 更新count时来保证互斥的
semaphore data_mutex = 1;		// 读/写的互斥保证
int count = 0;		// 记录读的进程数

void reader() {
    while(TRUE) {
        down(&count_mutex);			// 更新count需要加锁，防止多个读者并发更新
        count++;
        if(count == 1) down(&data_mutex); // 第一个读者需要对数据进行加锁，防止写进程访问
        up(&count_mutex);
        
        read();
        
        down(&count_mutex);
        count--;
        if(count == 0) up(&data_mutex);			// 最后一个读者离开，需要对读写锁解锁
        up(&count_mutex);
    }
}

void writer() {
    while(TRUE) {
        down(&data_mutex);
        
        write();
        
        up(&data_mutex);
    }
}
```

上面的情况可能会导致writer饿死，

```c
int readcount, writecount;                   //(initial value = 0)
semaphore rmutex, wmutex, readLock, resource; //(initial value = 1)

//READER
void reader() {
    <ENTRY Section>
    down(&readLock);                 //  reader is trying to enter
    down(&rmutex);                  //   lock to increase readcount
    readcount++;                 
    if (readcount == 1)          
        down(&resource);              //if you are the first reader then lock  the resource
    up(&rmutex);                  //release  for other readers
    up(&readLock);                 //Done with trying to access the resource

    <CRITICAL Section>
        //reading is performed

        <EXIT Section>
        down(&rmutex);                  //reserve exit section - avoids race condition with readers
    readcount--;                       //indicate you're leaving
    if (readcount == 0)          //checks if you are last reader leaving
        up(&resource);              //if last, you must release the locked resource
    up(&rmutex);                  //release exit section for other readers
}

//WRITER
void writer() {
    <ENTRY Section>
        down(&wmutex);                  //reserve entry section for writers - avoids race conditions
    writecount++;                //report yourself as a writer entering
    if (writecount == 1)         //checks if you're first writer
        down(&readLock);               //if you're first, then you must lock the readers out. Prevent them from trying to enter CS
    up(&wmutex);                  //release entry section

    <CRITICAL Section>
        down(&resource);                //reserve the resource for yourself - prevents other writers from simultaneously editing the shared resource
    //writing is performed
    up(&resource);                //release file

    <EXIT Section>
        down(&wmutex);                  //reserve exit section
    writecount--;                //indicate you're leaving
    if (writecount == 0)         //checks if you're the last writer
        up(&readLock);               //if you're last writer, you must unlock the readers. Allows them to try enter CS for reading
    up(&wmutex);                  //release exit section
}
```

We can observe that every reader is forced to acquire ReadLock. On the otherhand, writers doesn’t need to lock individually. Once the first writer locks the ReadLock, it will be released only when there is no writer left in the queue.

From the both cases we observed that either reader or writer has to starve. Below solutionadds the constraint that no thread shall be allowed to starve; that is, the operation of obtaining a lock on the shared data will always terminate in a bounded amount of time.

```
int readCount;                  // init to 0; number of readers currently accessing resource

// all semaphores initialised to 1
Semaphore resourceAccess;       // controls access (read/write) to the resource
Semaphore readCountAccess;      // for syncing changes to shared variable readCount
Semaphore serviceQueue;         // FAIRNESS: preserves ordering of requests (signaling must be FIFO)

void writer()
{ 
    down(&serviceQueue);           // wait in line to be servicexs
    // <ENTER>
    down(&resourceAccess);         // request exclusive access to resource
    // </ENTER>
    up(&serviceQueue);           // let next in line be serviced

    // <WRITE>
    writeResource();            // writing is performed
    // </WRITE>

    // <EXIT>
    up(&resourceAccess);         // release resource access for next reader/writer
    // </EXIT>
}

void reader()
{ 
    down(&serviceQueue);           // wait in line to be serviced
    down(&readCountAccess);        // request exclusive access to readCount
    // <ENTER>
    if (readCount == 0)         // if there are no readers already reading:
        down(&resourceAccess);     // request resource access for readers (writers blocked)
    readCount++;                // update count of active readers
    // </ENTER>
    up(&serviceQueue);           // let next in line be serviced
    up(&readCountAccess);        // release access to readCount

    // <READ>
    readResource();             // reading is performed
    // </READ>

    down(&readCountAccess);        // request exclusive access to readCount
    // <EXIT>
    readCount--;                // update count of active readers
    if (readCount == 0)         // if there are no readers left:
        up(&resourceAccess);     // release resource access for all
    // </EXIT>
    up(&readCountAccess);        // release access to readCount
}
```

## 1.9 实际操作系统的同步实现机制

### 1.9.1 Windows

对于单处理器，采用屏蔽中断；对于多处理器，采用自旋锁来保护共享资源，但是只采用自旋锁保护短代码段。内核确保绝不抢占有自旋锁的线程。

对于内核外的线程同步，提供了**调度对象**来实现同步。它有多种同步机制：互斥锁、信号量、事件、定时器等

（事件：类似于条件，当条件出现时会通知等待的线程；当条件没有到来时，线程就会被挂起）

调度对象有两种状态：触发状态 和 非触发状态。触发状态表示对象可用，非触发状态表示对象不可用，获取会造成阻塞。

互斥锁：在用户模式下是**临界区对象**，不需要内核干预就可以获取和释放锁，在多处理器系统上，当等待一个线程释放临界区对象时，会先进行自旋，如果一段时间后没有获得，那么会给一个互斥锁，并放弃CPU——高效，只有在争用的时候才给分配锁

### 1.9.2 Linux

Linux2.6之后，支持抢占内核，那么就存在同步问题。

Linux中最简单的同步方法：原子整数，对原子整数的操作是不会被中断的，包括读取数据、设置、自加自减等。

但是如果存在多个变量的抢占情况时，需要用到复杂的同步机制

- 互斥锁：用在内核中的临界区保护

- 自旋锁和信号量：SMP基本的是自旋锁，短时间操作就用它，如果长时间操作就用锁

  ​                               单处理器不用锁，而是禁止中断和启用中断

禁止中断和启动中断的策略：每个task在thread_info中维护一个变量：preempt_count，用来表示任务占有锁的个数，如果个数>0，表示当前线程占有锁，不能进行中断抢占；如果=0，表示不占有锁，那么可以进行中断

### 1.9.3 Pthreads API

被用户级别的线程所使用，提供了互斥锁、信号量、条件变量

互斥锁：

```c
#include<pthread.h>
pthread_mutex_t mutex;		// 定义互斥锁变量
pthread_mutex_init(&mutex, NULL);		// 初始化

pthread_mutex_acquire(&mutex);		// 获取锁，如果失败将会被挂起
phtread_mutex_release(&mutex);		// 释放锁
```

信号量：分为无名信号量、命名信号量

命名信号量，在文件系统中有实际名字，可以在多个进程之间进行共享

无名信号量：只能被一个进程的多个线程共享

```c
#include<semaphore.h>
sem_t sem;

sem_init(&sem, 0, 1);
```

# 2. 死锁

死锁的概念：组内的每个线程都在等待一个资源，而这个资源必须由组内的另一个进程释放（因为该进程也同样在等待，所以不可能进行下去了）。那么这些线程永远无法进行下去，浪费了系统资源。

而资源：可以是物理资源，eg：打印机、内存空间；逻辑资源：信号量、锁、文件等

eg：对于同一个资源：一个系统有2个打印机，线程A、B各持有一台，现在线程A、B均需要另一台才能继续下去，那么这两个进程就出现了死锁。

eg：对于不同资源：线程A占有资源a，等待资源b，线程B占有资源b，等待资源a，那么两者也是陷入死锁。

有些死锁不是必然发生的，而是需要根据一定的调度情况才会发生。

## 2.1 死锁的特征

### 2.1.1 死锁发生的条件

4个条件同时发生，才能引起死锁。

- **互斥**：资源处于非共享模式，即最多只能有一个进程能够占用；如果另一个进程尝试获得，那么必须要等待该线程释放才行
- **占有和等待**：该线程已经占有一个资源，并且在等待另一个资源
- **不可抢占**：已经分配给一个进程的资源不能强制性地被抢占，它只能被占有它的进程显式地释放。这边的抢占对象是**资源**
- **循环等待**：有两个或者两个以上的进程组成一条环路，该环路中的每个进程都在等待下一个进程所占有的资源。

可以使用资源分配图进行分析：是一个有向图线程$p_i$指向资源$r_j$，表示线程申请资源；资源$r_i$指向$p_j$，线程拥有该资源。**如果出现环路，那么可能存在死锁，如果没有环路，那么一定没有死锁**。

<img src="pic/RAG.png">

存在环但是不一定有死锁：

<img src="C:\Users\surface\AppData\Roaming\Typora\typora-user-images\image-20210331204124739.png" alt="image-20210331204124739" style="zoom: 43%;" />

## 2.2 死锁的处理方法

总的来说有4种方法：

- 预防死锁

  保证上面的必要条件有一个不成立

- 死锁避免

  事先得到线程申请资源和使用资源的信息，然后系统可以决定是否需要等待

- 检测死锁，然后恢复

- 忽视死锁，觉得不可能发生

### 2.2.1 忽视死锁（鸵鸟策略）

大部分操作系统都采用第三种解决方案

因为解决死锁问题的代价很高，因此鸵鸟策略这种不采取任务措施的方案会获得更高的性能。

当发生死锁时不会对用户造成多大影响，或发生死锁的概率很低，可以采用鸵鸟策略。

大多数操作系统，包括 Unix，Linux 和 Windows，处理死锁问题的办法仅仅是忽略它。

### 2.2.2 死锁预防

将死锁的四个条件：互斥、占用并等待、不可抢占、循环等待，破除一个就能不出现死锁。

#### 2.2.2.1 互斥

只有资源互斥才会发生死锁。但是这个不能作为预防条件，因为有些资源本来就是要求互斥的——这个是必要条件

#### 2.2.2.2 占用并等待

可以要求：

- 先获得所有要的资源，再进行执行；如果任何一个资源不得，那么就等待
- 可以边执行边申请，但是需要保证在申请时，释放所有持有的资源

但是存在的问题：

- 资源利用率比较低：有些资源已经占用，但是长时间得不到使用
- 发生饥饿：一个进程需要多个资源，那么只要有一个资源不可得就要等待，那么容易一直等待下去

#### 2.2.2.3 不可抢占

可以要求：在该线程等待另一个资源而不可得进入等待状态时，该线程占有的资源可以被需要的线程抢占走——资源可以被隐式释放。

只有当该线程获得申请的资源和之前占有的全部资源时，才能继续执行。

资源可抢占可以用在：状态可以保存和恢复的那些资源。eg：CPU、内存等，而信号量等不能

#### 2.2.2.4 循环等待

给资源统一编号，进程只能按编号顺序来请求资源。

如果申请的资源$R_j$，小于$R_i$，那么$>R_j$之后的资源需要全部释放掉，然后从$R_j$开始再次申请

那样就不会发生循环的情况。

——总结：死锁预防，从源头避免的死锁的问题，但是存在的问题是：资源利用率低、系统吞吐率低（有些资源申请了又被释放，然后再次申请，浪费大量时间）

### 2.2.3 死锁避免

在程序运行时避免发生死锁。需要知道线程如何申请资源：包括申请哪些资源、申请的顺序等

那么系统在每次进程申请资源时，计算这一步是否会发生死锁，如果发生死锁就先等待

系统需要考虑：现有可用资源、已分配的资源、每个线程将要申请的资源

#### 2.2.3.4 安全状态

安全的概念：存在一个执行序列，能够保证每个线程的分配要求均能满足，程序最终顺利执行。

安全序列$<P_1, P_2, ...P_j,....P_n>$，这个含义就是：对于每个$P_j$，$P_j$仍然可以申请的资源数小于当前可用资源数 + 之前所有进程(i < j)的占用资源总数。所以，即使$P_j$不能马上执行，也能等到前面的所有线程执行完成再执行

安全状态不是死锁状态，死锁状态一定是非安全状态。

<img src="C:\Users\surface\AppData\Roaming\Typora\typora-user-images\image-20210331230414786.png" alt="image-20210331230414786" style="zoom:67%;" />

eg：系统有12个这样的资源

<img src="C:\Users\surface\AppData\Roaming\Typora\typora-user-images\image-20210331230442579.png" alt="image-20210331230442579" style="zoom:67%;" />

可以构建出的安全序列为$<P_1, P_0, P_2>$

#### 2.2.3.5 银行家算法

一个小城镇的银行家，他向一群客户分别承诺了一定的贷款额度，算法要做的是判断对请求的满足是否会进入不安全状态，如果是，就拒绝请求；否则予以分配，如果此时还分配就会出现资金耗尽的情况。

单个资源的银行家算法就和上面的安全状态一样。

银行家算法主要用于：多个资源

<img src="pic/bankerAlog.png">

上图中有五个进程，四个资源。左边的图表示已经分配的资源，右边的图表示还需要分配的资源。最右边的 E、P 以及 A 分别表示：总资源、已分配资源以及可用资源，注意这三个为向量，而不是具体数值，例如 A=(1020)，表示 4 个资源分别还剩下 1/0/2/0。

检查一个状态是否安全的算法如下：

- 查找右边的**矩阵是否存在一行小于等于向量 A**。如果不存在这样的行，那么系统将会发生死锁，状态是不安全的。
- 假若找到这样一行，将**该进程标记为终止**，并将其已分配资源加到 A 中。
- 重复以上两步，直到所有进程都标记为终止，则状态时安全的。

（即，每次都记录的是全拿的，然后将这个线程当作执行完成的）

如果一个状态不是安全的，需要拒绝进入这个状态。

### 2.2.4 死锁检测

如果既不预防死锁又不避免死锁，那么就可能发生死锁，需要知道是是否发生了死锁，该如何解决

所以需要提供了：检查系统状态来确定是否出现死锁的算法；从死锁中恢复的算法

#### 2.2.4.1 每种资源只有单个实例的死锁检测

<img src="pic/deadlock1.png" style="zoom:80%;" >

（上图为资源分配图，其中方框表示资源，圆圈表示进程。资源指向进程表示该资源已经分配给该进程，进程指向资源表示进程请求获取该资源）

上图可以发现一个环，说明存在死锁的问题。

每种类型一个资源的死锁检测算法是通过检测有向图是否存在环来实现，**从一个节点出发进行深度优先搜索，对访问过的节点进行标记，如果访问了已经标记的节点，就表示有向图存在环，也就是检测到死锁的发生**。

#### 2.2.4.2 每种类型多个资源的死锁检测

<img src="pic/deadlock2.png">

上图中，有三个进程四个资源，每个数据代表的含义如下：

- E 向量：资源总量
- A 向量：资源剩余量
- C 矩阵：每个进程所拥有的资源数量，每一行都代表一个进程拥有资源的数量
- R 矩阵：每个进程请求的资源数量

进程 P1 和 P2 所请求的资源都得不到满足，只有进程 P3 可以，让 P3 执行，之后释放 P3 拥有的资源，此时 A = (2 2 2 0)。P2 可以执行，执行后释放 P2 拥有的资源，A = (4 2 2 1) 。P1 也可以执行。所有进程都可以顺利执行，没有死锁。

算法总结如下：

每个进程最开始时都不被标记，执行过程有可能被标记。当算法结束时，**任何没有被标记的进程都是死锁进程**。

1. 寻找一个没有标记的进程 Pi，它所请求的资源小于等于 A。
2. 如果找到了这样一个进程，那么将 C 矩阵的第 i 行向量加到 A 中，标记该进程，并转回 1。
3. 如果没有这样一个进程，算法终止。

#### 2.2.4.3 死锁恢复

- 利用抢占恢复

  不断抢占一些资源，直到恢复

- 利用回滚恢复

- 通过杀死进程恢复

  - 可以只杀死一个线程，看是否恢复，如果没有恢复继续杀，代价大，线程的计算结果都没有了

  - 可以杀死所有死锁的线程：开销大，每次杀死之后都需要进行死锁检测

    杀死的选择——策略决策，计算最小代价，这个是不同方向的考量



