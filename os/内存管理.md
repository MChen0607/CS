# 1. 内存管理

## 1.1 基本概念

对于内存单元来说，只关注地址流，而不关注这些地址的产生过程。

内存相关的硬件：CPU能够直接访问的是寄存器、内存、cache（为了提高访问速度，访问cache比访问内存快多了），不能直接使用磁盘。

每个进程都有单独的内存空间。并且进程间的内存空间互不干扰，因此需要将进程可以访问的范围做一个限制：用两个寄存器：**基地址寄存器 & 界限地址寄存器**。当在用户模式下，进程试图访问操作系统内存 or 其他进程的空间，那么会陷入操作系统，然后OS会将其处理为fatal-error。

**只有内核模式下的操作系统能够无限制的访问操作系统核用户的内存。**

### 1.1.1 地址绑定

在编译时，能够确定要访问的地址——**绝对代码**

在加载时，如果编译期间无法确定地址，需要生成**可重定位的代码**

在运行时，如果进程在执行时可以从一个内存移动到另一个内存，那么在执行时才能进行绑定

<img src="pic\image-20210402155336538.png" alt="image-20210402155336538" style="zoom: 40%;" />

可以看到程序的不同部分在不同时候被绑定。

### 1.1.2 逻辑地址空间 & 物理地址空间

CPU生成的地址为逻辑地址（虚拟地址），用户只生成逻辑地址，且看不到物理地址。

内存看到的地址为物理地址

从虚拟地址映射到物理地址，对应的是**内存管理单元MMU**。

### 1.1.3 动态加载

特点：只有一个程序被需要时，才能被加载。

### 1.1.4 动态链接和共享库

动态链接针对的是系统库，用户程序调用了系统库一起参与运行。

有的操作系统，只支持静态链接，即系统库只能和其他模块一起，通过加载程序，被合并到二进制程序映像中。

动态链接：在程序运行过程中，进行链接（静态链接是在运行之前，生成二进制文件时）

如果不能进行动态链接，必须要每个进程都有一个该API的副本。

动态链接中，二进制映像中，每个库引用都有一个**存根**，存根就是一段代码：指出如何定位到内存驻留库程序 or 如果不在内存中时应该如何加载库。

所以，第一次运行存根时：检查库是否在内存中，如果不存在需要加载，然后**用程序在内存中的地址替换存根**。然后，下次再执行该程序代码时，不需要再加载，直接到该地址运行即可——所以，所有进程只需要一个库程序的副本即可。

动态链接也能用户库的更新。库可以用新版本的库替代，而且使用该版本库的程序都会自动使用新的库。（如果没有动态链接，则需要重新链接才行）

而如果新旧版本之间不兼容 or 程序不期望使用新的库，可以带上版本，然后程序根据版本好来动态链接不同的库

## 1.2 交换

进程只有加载在内存中才能运行（当前要求是全部加载，之后可以改为加载需要运行的那部分），所以当进程不在运行时，可以暂时从**内存交换到备份存储结构**。

### 1.2.1 标准交换

标准交换：OS会维护一个进程的就绪队列，具体的进程的映像存放在内存 or 磁盘中，当调度器决定要执行一个进程时，会调用**分派器**，分派器会检查下一个要执行的（即将执行的）进程是否在内存中，如果不在内存中，会将内存中的某个进程换出，然后重新加载寄存器，开始运行下一个进程

所以：在交换过程中的主要耗时：数据传输。总的传输时间和交换的内存成正比。——所以，只需要传递真正用到的即可。

交换的过程中，需要保证进程是完全空闲的，如果进程不空闲，例如在等待IO时，就不能将该进程换出 or IO操作的执行只能使用操作系统的缓冲。

现代操作系统不适用标准交换，一般都进行改进。

常见的变种：正常情况下，禁止交换；当空闲空间低于某个阈值，就进行交换；如果空闲空间又高于阈值了，那么又禁用交换。

还有：只交换进程的部分，用来减少传输时间。

### 1.2.2 移动系统的交换

移动系统通常不允许交换，因为常采用的存储设备是闪存。

Android/IOS，都不采用交换，而是让用户自行放弃内存，对只读的数据直接进行删除；对于修改的数据不删除

## 1.3 连续内存分配

### 1.3.2 内存分配

这边的前提是：进程要运行必须要全部加载到内存中。

#### 1.3.2.1 多分区方法

是将内存划分成固定大小的多个分区，一个分区只能容纳一个进程，那么分区数就决定了该OS能够并发的进程数。

当一个分区空闲时，可以从磁盘加载一个新的进程进入。

#### 1.3.2.2 可变分区

操作系统维护一个表，哪些内存还未使用，然后如果要将进程加入到内存，需要找到适合大小的空闲内存块。

还维护了一个输入列表：需要进入内存的进程就会被加入输入列表，按照调度算法进行排序，内存不断分配给进程（进程不断加入到内存），直到内存余量不够分配给下一个进程（也可以对输入队列进行搜索，看是否有需求较小的进程满足要求）

那么内存块是如何分配的呢？——动态内存分配：

- **首次适应**：从头开始找第一个符合要求的空闲内存块，或者从上一次分配结束的点作为起点进行分配（下一次匹配）
- **最优适应**：遍历空闲列表，找到最适合的大小
- **最差适应**：遍历空闲列表，  分配最大的空闲内存块

#### 1.3.2.3 碎片

分为内碎片和外碎片。

不管如何优化：如果有N个可分配块，那么可能有0.5N个外碎片，即1/3的内存不能被使用——50%规则。

外碎片的解决方法之一是：**压缩**，就是将分散在内存中的内存移动到一起，那么能将所有的空闲内存块全部合并。

## 1.4 分段

一开始引入的分段，主要是进程的内存是由多个部分的组成：代码段、数据段、栈段、堆段。

所以，逻辑的地址空间就是由一组段构成的。

而段是编号的，而段内是通过举例段首的偏移得到的。

所以逻辑地址：由有序对组成的：**`<段号， 偏移>`**

eg：对于C语言，C语言编译器会创建如下段：

- 代码段
- 全局变量段
- 堆
- 栈段
- 标准的C库段

对于虚拟地址可以通过**<段号， 段内偏移>**计算得到，那么对应的物理地址还需要映射，这个需要由硬件来帮助支持。

段映射到物理地址：**通过段表实现**，段表的每个条目有一个**段基地址和段界限**——唯一确定一个段

<img src="pic\image-20210401220740186.png" alt="image-20210401220740186" style="zoom:67%;" />

eg：内存布局：

<img src="pic\image-20210401220841067.png" alt="image-20210401220841067" style="zoom: 50%;" />

问题：由于段的大小是不确定的，且只要有足够大的空闲空间就会进行分配，那么必然产生较多外碎片。

## 1.5 分页⭐

分段，分配的段是大小不确定的。而分页：每次分配的大小都是固定的，常见为4KB。

优势：**分页能够避免外碎片和内存压缩**，也避免了将不同大小的内存块匹配到交换空间的麻烦（段的进入和换出都需要找到合适的位置进行放置）

——因此，分页成为主流的内存管理方法。

但是，分页还是会产生内碎片。

如果页面小，那么产生的内碎片就会较少，但是需要维护的页表就相应的变大；如果页面大，那么产生的内碎片就较多，但是页表较小

### 1.5.1 基本方法

将物理内存分为固定大小的块，称为**帧** or 页帧。

将逻辑内存也分为固定大小，称为**页** or 页面

所以当需要一个进程时，将进程从磁盘加载到内存的**可用帧**。备用存储也会被划分为固定大小。

硬件支持：

<img src="pic\image-20210401223557921.png" alt="image-20210401223557921" style="zoom:67%;" />

**逻辑地址：页码 + 页偏移**，页码作为**页表**的索引。

通过页码在页表中找到逻辑地址所在的对应的物理地址帧的基地址。

页码 -> 基地址，基地址 + 页偏移 = 物理地址（和段的映射类似）

页大小由硬件来决定。页大小是2的幂次（为了方便将逻辑地址转换为页码 和 页偏移，直接将逻辑地址转换为二进制表示，然后高地址就是页码，低地址就是页偏移）。

<img src="pic\image-20210401224146326.png" alt="image-20210401224146326" style="zoom:80%;" />

可以发现：分页就是一种动态的重定位，**每个逻辑地址由分页硬件绑定了对应的物理地址**

如果32位CPU，那么能够访问的物理地址为$2^32 = 4GB$范围；而如果采用分页，且每页大小为4KB，那么能够操控的逻辑地址范围为$2^{12} * 2^{32} = 2^{44} = 16TB$物理范围，所以使用分页，能够使使用的逻辑地址范围大于物理地址

在将进程加载进入内存时，需要看内存中是否有足够的物理帧来导入（针对需要将整个进程加载进入内存的场景）。OS会管理物理内存，它会维护一个**帧表**：记录哪些物理内存还是空闲状态。

### 1.5.2 硬件支持

采用了分页，将逻辑地址和物理地址进行映射，那么**页表**就成为关键的信息。

页表的硬件实现有多种，最简单的是：将页表用一组专用的寄存器保存。查询和转换是十分高效的。但是在进行上下文切换的时候，需要保存的信息又新增了该专用寄存器。

——当页表较小的时候，可以用专用寄存器。但是现代计算机的页表都很大，而寄存器是一种十分珍贵的资源，所以不能用寄存器来存储整个页表。采用：**页表基地址寄存器PTBR**，然后将页表存储在内存中。PTLR保存页表的大小

那么进行页帧转换所花的时间：**PTBR + 页码** 进行内存访问，找到页表中对应的帧码，然后**帧地址 + 页偏移** 进行内存访问，找到物理地址的内容

——**需要两次内存访问**

#### 1.5.2.1 TLB

所以需要再引入**转换表缓冲区TLB**，它存放在cache中

**TLB的数据结构：key-value。**当给定值时，会在TLB中和所有的key进行比较，找到对应的值——查找方式是指令流水线，所以速度很快。

TLB不会很大，**只包含少数的页表条目**。现在发展是从无TLB到多层TLB（类似于多层cache）

如果页码不在TLB——**TLB未命中**，那么需要从内存中的页表中将该条找到，并且添加到TLB中，如果TLB满了，需要进行置换（置换算法有LRU等），访问页表的过程可以通过硬件直接处理，也可以中断处理。

当然，有些TLB可以将部分条目固定下来，一般重要内核代码的条目是固定的，不会被替换出去。

<img src="pic\image-20210402093115202.png" alt="image-20210402093115202" style="zoom:80%;" />

有些TLB还存储**地址空间标识符ASID**，**它用来唯一标志每个进程，用来进行地址空间保护**，当TLB进行虚拟地址解析的时候，会先判断当前进程的ASID和虚拟页相关的ASID是否一致，如果不一致那就判定为TLB未命中。

——TLB是一个硬件功能，但是需要了解其特性，并根据不同的硬件TLB的设计，来实现分页操作。

#### 1.5.2.2 命中率

TLB命中页码的次数占总次数的比例为命中率

eg：80%命中率，表示有80%的时间可以找到需要的页码

那么可以求得有效内存访问时间 = 0.8 * 一次内存访问时间 + 0.2 * 2 * 一次内存访问时间

### 1.5.3 保护

内存保护：就是防止CPU去访问一个非法的物理地址，or 去访问当前进程外的空间。

实现：通过页表中的帧保护位来实现

- 用一个位定义：只可读 or  可读可写，然后在计算页对应的帧的时候，来检查保护位来判断是否要对只读页进行写操作

  如果是，那么会产生硬件陷阱 or 内存保护冲突

- 用一个位定义：有效 or 无效位，表示页表中的每一个条目对当前进程是否有效

  有效：该值在进程的逻辑地址范围内

  无效：页不在逻辑地址范围。

  出现非法访问也会导致内核陷阱

  <img src="pic\image-20210402102309959.png" alt="image-20210402102309959" style="zoom:80%;" />

- 如果为页表的每个条目都设置一位，比较浪费，可以使用一个寄存器：页表长度寄存器PTLR，来表示当前进程的逻辑地址的有效范围

### 1.5.4 共享页

分页能够进行页面共享，即多个进程大家可以映射同一个物理地址。

针对可以共享的：那么多个进程只读同一份副本

如果是进程私有的，那么每个进程必须要单独保存一份副本

### 1.5.5 页表结构

分页的关键就是构建页表，而现代计算机系统都支持大逻辑地址空间：$2^{32} - 2^{64}$（CPU指令长度）

所以页表本身可以很大。

eg：4KB的页大小，对于$2^{32}$的逻辑地址，有$2^{20}$，大约100万条，如果每一条有4字节，那么有4MB的页表存储空间。

#### 1.5.5.1 分层分页

所以可以将页表再次分页，用两层分页算法。

4MB的页表，可以继续分为4KB大小的，那么就有$2^{10}$页，共有$2^{10}$条目

<img src="pic\image-20210402104214743.png" alt="image-20210402104214743" style="zoom:80%;" />

所以逻辑地址可以划分为：`<外部页表索引，外部页表偏移，页内偏移>`

<img src="pic\image-20210402104329275.png" alt="image-20210402104329275" style="zoom:67%;" />

对于32位系统来说，还是可行的。但是64位系统，不大适用了，可能需要多次分级，效果还不是很好

<img src="pic\image-20210402104638297.png" alt="image-20210402104638297" style="zoom:80%;" />

#### 1.5.5.2 哈希页表

适用于大于32位的地址空间，虚拟页码就是哈希值，数据结构就是哈希表，然后根据虚拟页码找到对应的index，然后在index里面找，不匹配就找链表上的下一个结点

所以这个的性能关键是：哈希函数的设计。

变体：聚簇页表，类似于哈希页表，但是聚簇页表的每个条目都会指向多个物理帧。所以单个页表条目能够指向多个物理地址的帧。

#### 1.5.5.3 倒置页表

针对页表是按照虚拟地址排序的，所以页表可能存在很多条目，存储页表就需要大量的物理内存，可以采用——**倒置页表**。

倒置页表概念：只有真正存在的帧，才会在倒置页表中存在一个条目。所以页表中是按照物理地址排序的（可以说是存储了整个物理地址）

所以：**整个系统只有一个页表，且每个物理地址帧对应一个条目**

<img src="pic\image-20210402132344618.png" alt="image-20210402132344618" style="zoom:67%;" />

和普通的页表项相比，要求每个条目保存一个地址空间标识符，用来标志该条目对应的进程，那么能确保：具体进程的每个逻辑页都能对应到相应的物理帧。

具体的应用：虚拟地址是一个三元组`<进程id，页码，偏移>`，所以在查找时，是`<进程id，页码>`去倒置页表中查找，需要同时匹配进程id和页码才算是，如果查找到了，那么`i+页偏移`（i就是页表中的偏移）；如果找不到，就是非法地址访问。

优势：减少了页表的空间

缺点：由于是按照物理地址排序，而查找是通过逻辑地址，所以可能需要遍历整个页表才能判断是否找到。耗时变多。

——可以用一个哈希表来限制搜索条目。而每次访问哈希表也是需要访问内存的（可以先访问TLB）

所以，如果是哈希表+倒置页表的设置下，需要进行两次内存访问。

而共享内存就比较困难，因为是按照物理地址创建页表的，所以一个物理地址能有一个条目。

——允许页表包含一个虚拟地址到共享内存的条目。

## 1.6 应用

### 1.6.1 IA-32架构

IA-32的内存管理可以分为：**分段、分页**。

CPU生成逻辑地址，分段单元映射成线性地址，分页单元将线性地址映射成物理地址。

<img src="pic\image-20210402140403479.png" alt="image-20210402140403479" style="zoom:66%;" />

IA-32的分段：每个段大小上限为4GB，每个进程段数目上限为16K。

进程的逻辑地址空间被划分成两部分：最多由8K个段，存储进程的私有段，该信息保存在局部描述符：LDT；另一部分最多8K个段，所有进程共享，该信息保存在全局描述符：GDT。

逻辑地址是二元组`<选择器，偏移>`

选择器：

<img src="pic\image-20210402140148856.png" alt="image-20210402140148856" style="zoom:80%;" />

s：段号（8K个上限），g：GDT/LDT，p：保护信息。

偏移是一个32位的数字（段大小是4GB上限）

LDT、GDT由8个字节组成：包括段的基地址、界限等。

<img src="pic\image-20210402140436674.png" alt="image-20210402140436674" style="zoom:67%;" />

IA-32的分页

页可以是4KB、4MB大小，

对于4KB，是使用二级页表（就是1.5.5.1的结构），如果配置了4MB的大小，那么通过最外层页表直接指向物理地址。

<img src="pic\image-20210402140644146.png" alt="image-20210402140644146" style="zoom:70%;" />

<img src="pic\image-20210402140725045.png" alt="image-20210402140725045" style="zoom:67%;" />

（可配置的页表结构）

### 1.6.2 Intel x86-64

采用多级分页，支持48位虚拟地址（而不是64位），页面大小为4K、2MB、1GB

<img src="pic\image-20210402135424908.png" alt="image-20210402135424908" style="zoom:80%;" />

### 1.6.3 ARM架构

用在移动设备上

支持的页面：4KB、16KB的页；1MB、16MB的页（段）。

一级分页用于1MB、16MB的段，二级分页用于4KB、16KB的页。

# 2.虚拟内存管理

## 2.1 概念

引入虚拟内存的原因：进程在执行时，不必完全处于内存（有些程序指令是几乎执行不到的，eg：异常处理、大数据结构等），那么程序可以大于物理内存。从而实现逻辑内存和物理内存的分离。

——**让物理内存扩充成更大的逻辑内存，从而让程序获得更多的可用内存**。

虽然，进程不必完全处于内存，但是执行到的指令必须处于物理内存中。

用虚拟内存的优势：

1. 程序在编写的时候不需要再考虑设备的物理内存情况，用户可以给通用的固定的虚拟内存空间写程序，降低难度
2. 每个程序占用较少的物理内存，那么有更多的程序能够加载，提高CPU的利用率和吞吐量，且不会增加响应时间 or 周转时间
3. 加载or交换程序到内存的IO变少，所以程序运行速度加快

**进程的虚拟地址空间**：进程如何在虚拟内存中进行存放的

- 从地址0开始，一直连续的到最大值；
- 物理地址按照帧来分布，通过**MMU**来实现虚拟地址到物理地址的映射
- 在进程中，堆是允许向上生长的（向高地址），栈是向下生长的（向低地址）。所以，只有当栈/堆扩展的时候才需要实际的物理页

<img src="pic\image-20210401093653574.png" alt="image-20210401093653574" style="zoom:72%;" />

除了物理内存和虚拟内存分离的好处，还有共享页的好处：

- 将共享库映射到虚拟内存中，系统库可以实现共享。在不同的进程中这些系统库虽然不是同一个虚拟地址，但是转换成的物理地址肯定是指向同一个的。
- 并且，也能简单的实现共享内存

<img src="pic\image-20210401131223130.png" alt="image-20210401131223130" style="zoom:67%;" />

## 2.2 请求调页

在虚拟内存中：从磁盘加载可执行程序到内存的策略：**仅在需要的时候加载页面**，那些从未访问的页就不会被调用

请求调页系统，使用的是**惰性交换器**，除非该页面需要用到，否则是不会加载到内存中的。

请求调页的关键：**帧分配算法、页面置换算法**。

- 页面置换算法：如果内存中无空闲帧，那么需要页面置换，该如何选择要替换的帧
- 帧分配算法：如果有多个进程在内存中，需要决定为每个进程分配多少帧

### 2.2.1 基本操作

只有要使用的页才会被调入内存，那么页表该如何表示呢？

<img src="pic\image-20210402163643388.png" alt="image-20210402163643388" style="zoom:70%;" />

可以使用**有效位-无效位**进行表示，当该位被设置为有效时，表示关联的页面是合法的，并且在内存中；如果被设置为无效，表示在当前的进程逻辑中无效，或者是有效的只不过在磁盘中尚未导入

如果进程试图访问的页面在内存中驻留，那么没问题；如果访问的页面不在内存中，那么发生**缺页错误**。

那么该如何处理呢？——将所需页面加入到内存中即可：

1. 检查该进程的内部表（和PCB一起保存的），看缺页是有效的内存访问，还是无效的
2. 如果引用无效，终止进程；如果引用有效但是尚未调入内存，需要将其调入
3. 找到一个内存空闲帧
4. 从磁盘中找到需要的页面，将该页面读到上面的空闲帧中
5. 当读取完成后，修改内部表和页表，标志该页已经进入内存
6. 重新启动被陷阱中断的进程

刚开始启动的时候，可能该进程没有一个内存页面也没有，所以执行第一个指令的时候就发生缺页异常，所以需要立即调用页面进内存——纯请求调页：只有在需要的时候才进行调页。

理论上，程序的指令执行可能会访问多个页面（就有可能发生多个缺页）：一个用于指令，多个用于数据，那么性能将会很差，但是根据**局部引用性质，不会发生如此极端情况**

**请求调页的关键要求：缺页错误处理之后，能够重启启动任何被中断的指令。**

### 2.2.2 请求调页的性能分析

**有效访问内存时间 = (1 - p) * 内存访问时间 + p * (缺页处理开销 + 页面换入耗时 + 页面换出耗时)**

缺页错误的处理的具体流程：

1. 陷入操作系统
2. 保存用户寄存器和进程状态
3. 确定中断是为缺页错误
4. 检查页面引用是否合法，并且确定页面在磁盘的位置
5. 从磁盘读入到空闲帧
   1. 在磁盘队列中等待执行，直到读请求被处理
   2. 等待磁盘的寻道或延迟时间
   3. 开始磁盘到内存的帧传输
6. 在等待过程中，CPU 将交由其他进程执行
7. 收到来自IO子系统的中断——表示中断完成
8. 处理该中断，需要保存当前进程的寄存器和进程状态
9. 确认中断是来自磁盘的
10. 修正页表和内部表，用来表示该页已经在内存中了
11. 该进程从等待态变成就绪态，然后等待CPU调度
12. 被调度，恢复2保存的寄存器和进程状态，再重新执行被中断的指令

通过计算发现，有效访问时间和缺页错误率成正比，所以为了不影响计算机执行性能，保证400,000次内最多有1次缺页错误

## 2.3 写时复制

主要针对父进程和子进程，由于fork()时，父进程会生成一个完全一样的副本来作为子进程的初始内容。那么，在fork()进程最初创建的时候，可以采用**共享页面的方式**——即，父子都共用同一个物理帧，从而避免申请页面的操作。

**只有当任何一个进程写入共享页面时，才会创建共享页面的副本然后将其放到对应进程的地址空间中**——这个就是写时复制。

这个之后，对该页面的修改就都在该副本上了，而不会去修改共享页面。

注意：**只有可写页面才能标记为写时复制，对于只读的页面（eg：代码页面），一直能进行共享**

写时复制被很多OS采用。

针对写时复制特性的页面，许多操作系统为其提供了空闲页面池，就是预先分配一些空闲的内存页面，当需要创建副本的时候，就从页面池中取出一个复制即可

OS会为这些页面进行初始化：**按需填零技术**，就是OS对这些页面在需要分配之前会先填0，从而清除之前的内容。

Linux里面提供的`vfork()`就是fork的变种，fork是写时复制，而vfork是将父进程挂起，而子进程使用父进程的地址空间，所以如果子进程修改任何页面都会影响父进程。

## 2.4 页面置换⭐

页面置换发生在：发生缺页错误，需要从磁盘中将页面加载到内存，但是内存中已经不存在空闲帧了，所以需要将页面进行替换。

### 2.4.1 基本页面置换

#### 2.4.1.1 基本算法

如果没有空闲帧，那么查找一个当前不在使用的帧进行释放，那么就有新的空闲帧了。

发生缺页错误以及之后的具体操作：

1. 找到缺页页面的磁盘位置

2. 找到一个空闲帧

   如果有，就使用它

   如果没有，就用页面置换算法选择一个**牺牲帧**。并将牺牲帧的内容写回到磁盘对应的位置，并且修改对应的页表和其他表，标志该帧已经不在内存中了

3. 将需要的页面读入空闲帧，然后也需要修改页表和其他表，标志该帧已经在内存中了

4. 从发生缺页错误的位置，重新开始执行

——所以，对于进行替换，那么需要一个进入、一个出去，所以**加倍了缺页错误的处理时间**

#### 2.4.1.2 优化

可以使用**脏位减小开销**，这个是由硬件控制的，如果当前页面的内容发生了改变，脏位都会被置位，表示修改过了。只有脏位被置位的页面在换出时将会被写回磁盘，其余均不会。

（所以，只读页面就减少了写回的操作），那么这样能够降低一半的IO时间

——下面就是不同的页面置换算法

**优劣衡量：最小缺页错误率**，针对特定的内存引用串，运行某个算法，计算缺页错误的数量

### 2.4.2 FIFO页面置换

按照进入内存时间，选择最早进入内存的帧进行替换。

用一个FIFO队列管理所有的内存帧，按照进入内存时间进行排序，所以每次被换出的都是队首页面，每次加入的都是队尾页面

优势：数据结构简单，且易于理解。

缺点：将那些经常被访问的页面换出，导致缺页率升高。

且存在一个异常：当分配帧的数量增加，缺页错误率反而增加了。——**belady异常**

eg：

```
1, 2, 3, 4, 1, 2, 5, 1, 2, 3, 4
```

帧数为3，发生9次缺页；帧数为4，发生10次缺页。

### 2.4.3 最优页面置换

最优的算法：置换最长时间不会用的页面。

这个是所有算法中最低的缺页率的。

是一种**理论上的算法，因为无法知道一个页面多长时间不再被访问。**

但是，该算法可以作为一个下限基准，用来与其他算法做个比较。

eg：帧大小为3，并有如下页面引用序列：

```
7，0，1，2，0，3，0，4，2，3，0，3，2，1，2，0，1，7，0，1
```

最小缺页数为9。

### 2.4.4 LRU页面置换

FIFO是看过去的时间；OPT是看将来的时间，LRU看过去使用页面的情况

LRU：是最近最少使用算法，将页面和上次使用时间进行关联，每次替换的都是最近最不常用的页面。

上面的序列，缺页次数为12次

Java中的数据结构就是linkedHashMap，可以用来方便的实现LRU。

OPT和LRU算法都是同一类算法，都能保证没有belady异常。

**它们都是堆栈算法**，能够证明的是：帧数为n的内存页面集合是n+1长度的页面集合的子集。

显然的是：帧长度为n，那么这n个页面就是最近引用的n个页面，而帧长变成n+1，那么这n个页面还是最近被引用的n个页面，还是会在内存中的。

### 2.4.5 近LRU页面置换

主要是很多硬件不支持真正的LRU算法，所以我们需要改进一下。很多系统都支持通过**引用位**来进行支持——就是在一段时间内统计哪些页面最近被使用了，哪些没有被使用，从而判定哪些是可以作为牺牲帧的。

#### 2.4.5.1 额外引用位算法

通过定期记录引用位，为页表中的每个页面保留一个8位的字段，定时器定时（eg：100ms）对该字段进行操作：将最近的引用位移动到最高位，其他整体向右移动1位，抛弃最低位。所以8次之后，就能看到在8个周期内，这些页面的使用情况：0000 0000 ——在8个周期中没有一次被用到；1111 1111——每个周期都有被使用；1100 0101，0101 1111，前者是更为最近使用的。所以我们只需要选择里里面值最小的，就是要被替换的牺牲帧，如果遇到相同的最小值，可以将它们都置换出去 or 用FIFO选择

#### 2.4.5.2 第二次机会算法

基本算法是FIFO算法，再加上引用位，如果引用位为0，那么直接进行置换；如果引用位为1，那么本轮不选择它替换（给他第二次机会），并且将引用位置0，按照FIFO找下一个页面。

所以所以获得第二次机会的页面，在其他页面被置换之前都不会被置换出去。一个页面如果经常被使用，那么久不会被替换掉。

实现算法：时钟算法，是维护一个**循环的FIFO队列**。

所以最极端情况下，第一次遍历队列时，给每个页面都第二次机会，引用位均重置为0，然后第二次遍历的时候，还是将FIFO最前面的页面删除了——退化成FIFO算法

<img src="pic\image-20210402215912149.png" alt="image-20210402215912149" style="zoom:80%;" />

#### 2.4.5.3 增强版第二次机会算法

对每个页面都有2个位——**(引用位， 修改位)**

- (0, 0) 最近没有使用，且没有修改的页面
- (0, 1) 最近没有使用，但是有修改过的，不大好进行置换
- (1, 0) 最近使用过，但是没有修改过，可能很快就会被再次使用
- (1, 1) 最近使用过，且修改过

所以使用第二次机会算法，然后选择优先级最低的页面进行替换

优势：考虑了IO的代价。

### 2.4.6 基于计数的页面置换

- 最不经常使用的：置换计数最小的页面，但是也存在局部性问题，某个页面在某个阶段经常被使用，而过了这段就不怎么被使用了，所以计数需要定期向右移动1位，按照指数的衰减方式来平均计数。
- 最经常使用的：最小计数的页面可能是刚被引入，且尚未使用的

### 2.4.7 页面缓冲算法

针对牺牲帧需要写回磁盘，这个过程较为耗时，那么将牺牲帧写入缓冲池的空闲帧，那么能够尽快恢复进程的运行，而不用等待牺牲帧写回才能将需要的帧写入。

扩展：维护一个修改帧的页表，当调页设备空闲时，选择一个修改帧写回磁盘，然后重置修改位——当作该页面没有被修改过

扩展2：空闲帧池中存放被换出的，但是未发生修改的页面，当它再次需要的时候可以直接从池中取出，而不需要IO操作

这个可以用对FIFO算法进行补充。

### 2.4.8 应用程序与页面置换

不同的应用程序对程序、数据的访问有自己的特性，而OS的页面置换算法是面向通用情况的。所以针对自己提供了IO缓冲和内存管理的应用，OS可以选择不管理，允许应用直接操作磁盘，而不是通过文件系统。

## 2.5 帧分配

主要讨论：每个进程要分配多少帧

算法：

- 平均分配

- 比例分配：所有要进入内存的进程的页面数进行求和，然后再计算出每个进程的占比，然后分配内存的帧

  （也可以按照优先级来进行占比分配）

页面置换的算法还可以分为：全局置换和局部置换

- **全局置换**：可以从内存帧的任意一个进行置换，所以存在置换另一个进程的帧的情况（前面的置换算法默认是这个）
- **局部置换**：只能从自己进程中占有的帧中选择一个进行置换

全局置换不能控制进程自己的缺页率，因为它的缺页情况还取决于其他进程的调页情况；而局部置换只跟进程本身有关。

但是，局部置换算法不能使用其他进程的帧，导致其他进程其实很少使用的帧但是不能替换

所以，从整体吞吐量来说，全局置换有更好的表现，所以常用。

## 2.6 系统抖动

**一个进程的调页时间大于执行时间——系统抖动**

抖动会造成性能问题。

可以发现一个进程执行的局部性模型：随着进程的执行，它从一个局部移动到另一个局部。eg：一个函数被调用时，就定义了一个新的局部。

目前防止抖动的方法：可能的情况下尽量提供足够的物理内存来避免抖动和交换。

## 2.7 内存映射文件

采用标准的`open()、read()、write()`可以顺序读取磁盘文件，每个文件的访问都需要先进行系统调用，后进行磁盘访问。

也可以采用虚拟内存技术，将文件访问作为常规内存访问——**内存映射**。就是让一部分虚拟内存和文件进行逻辑关联。

实现：将每个磁盘块映射到一个或者多个内存页面。初始时，文件访问按照普通的调页申请来，如果发生缺页错误就从磁盘中获取，然后文件部分就被放到了物理内存中，然后之后的文件访问就按照正常的内存访问来了。

对于数据共享：可以将文件加载到物理地址，然后进程通过虚拟地址映射到同一个物理地址，就实现了文件内容的共享

## 2.8 分配内核内存

分配内核内存不同于用户模式下的进程页申请：

- 内核需要为不同大小的数据结构请求内存，所以应该节省的使用内存，最小化碎片——所以，一般不采用页大小来分配
- 要求分配的内存常驻于内存

### 2.8.1 Buddy算法

按照2的幂次进行分配，会对内存块进行分裂和合并。每次分裂都分裂为2部分，这两部分互称为buddy。

### 2.8.2 slab算法

一个slab由一个或者多个物理页构成，每个cache由一个或者多个slab构成。一个cache存储单一的内核数据结构对象。在cache刚创建时，若干标记为free的对象被分配到cache。cache中能存储的对象个数取决于slab的大小

eg：12KB的slab，可以存储6个2KB的对象。

当内核需要创建该数据结构的新对象时，可以从cache上选择一个空闲对象进行赋值，然后标记为used。

所以slab可能存在3种状态：

- full
- empty
- partial：部分有占用，部分空

slab分配器会从部分空的slab种选择空闲对象来满足，如果slab为full，那么选择empty的slab进行分配；如果全为full，那么向物理页再次申请slab进行分配。

优点：

- 没有碎片
- 快速满足内存要求

——可以发现，它是按照要分配的内存的块特性提前申请一个空间来存储，所以一个slab上只有一类内存块类似于内存池

<img src="pic\image-20210402231959680.png" alt="image-20210402231959680" style="zoom:80%;" />

## 2.9 其他注意事项

### 2.9.1 预调页面

纯请求调页，在进程刚开始运行的时候会发生大量缺页错误。所以需要在运行前提前将要用到的页面加载进内存。但是，也存在预先调用的页面并没有被使用

### 2.9.2 页面大小

需要选择一个合适大小的页面：

- 页面太大：容易造成内碎片较多
- 页面太小：易发生缺页，导致频繁的IO操作

——所以没有最优解，只有相对较好的，且还需要根据不同的场景

### 2.9.3 TLB范围

TLB本身存储也需要内存，且要在有限的内存中表达尽量多的内存范围。

方法之一：增加页面大小，但是容易造成内碎片的问题。

为了更好的管理内存，操作系统将内存抽象成地址空间。每个程序拥有自己的地址空间，这个地址空间被分割成多个块，每一块称为一页。这些页被映射到物理内存，但不需要映射到连续的物理内存，也不需要所有页都必须在物理内存中。当程序引用到不在物理内存中的页时，由硬件执行必要的映射，将缺失的部分装入物理内存并重新执行失败的指令。

### 2.9.4 程序本身

用一个经典的例子来看

```c
// 如果页面存储数组是按照行来存储的，而遍历是按照列来遍历的，那么会不断发生缺页异常。如果页面大小为128字，那么会发生128 * 128次缺页错误
for (j = 0; j <128; j++)
    for (i = 0; i < 128; i++)
        data[i,j] = 0;

// 会发生128次缺页错误
for (i = 0; i < 128; i++)
    for (j = 0; j < 128; j++)
        data[i,j] = 0;
```

## 补充：

### 段页式

程序的地址空间划分成多个拥有独立地址空间的段，每个段上的地址空间划分成大小相同的页。这样既拥有分段系统的共享和保护，又拥有分页系统的虚拟内存功能。

### 分页与分段的比较

- 对程序员的透明性：分页透明，但是分段需要程序员显式划分每个段。
- 地址空间的维度：分页是一维地址空间，分段是二维的。
- 大小是否可以改变：页的大小不可变，段的大小可以动态改变。
- 出现的原因：**分页主要用于实现虚拟内存，从而获得更大的地址空间；分段主要是为了使程序和数据可以被划分为逻辑上独立的地址空间并且有助于共享和保护。**